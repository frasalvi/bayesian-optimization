# Bayesian optimization for weight initialization of gradient-based methods
We investigate if using Bayesian optimization to fit a Gaussian process for modelling a loss function as a means to find a good starting weight initialization for SGD can improve convergence compared to random initialization.

## Demo
Demos are made available in this repository as three .ipynb notebooks (Rosenbrock, Rastrigin, NN.ipynb). The notebooks cover the results from optimizing the Rosenbrock and Rastrigin functions as well as the neural network for the titanic dataset.

## Results
The results are presented in the report, available in this repository.

